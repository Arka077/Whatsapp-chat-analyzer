"""
Chat message preprocessing and parsing
"""

import re
import pandas as pd
from datetime import datetime
import uuid

def is_system_message(user, message):
    """Check if a message is a system message or bot response"""
    system_keywords = [
        'group notification', 'added', 'removed', 'created group',
        'left', 'calls are end-to-end encrypted', 'learn more',
        'messages are generated by ai', 'this message was deleted',
        'meta ai', 'only people in this chat', 'meta can'
    ]
    
    message_lower = message.lower()
    user_lower = user.lower()
    
    # Check if it's a system message or AI response
    if user_lower in ['group_notification', 'meta ai', 'system']:
        return True
    
    for keyword in system_keywords:
        if keyword in message_lower or keyword in user_lower:
            return True
    
    return False

def preprocess(data):
    """
    Preprocess WhatsApp chat export data
    Returns DataFrame with parsed messages and metadata
    """
    pattern = r'\d{1,2}/\d{1,2}/\d{2,4},\s\d{1,2}:\d{2}\s[ap]m\s-\s'
    
    messages = re.split(pattern, data)[1:]
    dates = re.findall(pattern, data)
    
    df = pd.DataFrame({'user_message': messages, 'message_date': dates})
    df['message_date'] = df['message_date'].astype(str).str.replace(r'\s-\s$', '', regex=True).str.strip()
    df['message_date'] = pd.to_datetime(df['message_date'], format='%d/%m/%Y, %I:%M %p')
    
    df.rename(columns={'message_date': 'date'}, inplace=True)
    
    users = []
    messages_list = []
    for message in df['user_message']:
        entry = re.split(r'([\w\W]+?):\s', message)
        if entry[1:]:
            users.append(entry[1])
            messages_list.append(" ".join(entry[2:]).strip())
        else:
            users.append('group_notification')
            messages_list.append(entry[0].strip())
    
    df['user'] = users
    df['message'] = messages_list
    df.drop(columns=['user_message'], inplace=True)
    
    # Mark system messages
    df['is_system_message'] = df.apply(lambda row: is_system_message(row['user'], row['message']), axis=1)
    
    # Add temporal features
    df['only_date'] = df['date'].dt.date
    df['year'] = df['date'].dt.year
    df['month_num'] = df['date'].dt.month
    df['month'] = df['date'].dt.month_name()
    df['day'] = df['date'].dt.day
    df['day_name'] = df['date'].dt.day_name()
    df['hour'] = df['date'].dt.hour
    df['minute'] = df['date'].dt.minute
    
    # Add period (hour range)
    period = []
    for hour in df['hour']:
        if hour == 23:
            period.append(str(hour) + "-" + str('00'))
        elif hour == 0:
            period.append(str('00') + "-" + str(hour + 1))
        else:
            period.append(str(hour) + "-" + str(hour + 1))
    
    df['period'] = period
    
    # Add unique message ID
    df['message_id'] = [str(uuid.uuid4()) for _ in range(len(df))]
    
    # Add language detection
    df['language'] = df['message'].apply(detect_language)
    
    # Add message length
    df['message'] = df['message'].astype(str)
    df['message_length'] = df['message'].str.len()
    
    return df


def detect_language(text):
    """Detect language: english, hinglish, or benglish"""
    try:
        # Check for Bengali script
        if re.search(r'[\u0980-\u09FF]', text):
            return 'benglish' if re.search(r'[a-zA-Z0-9]', text) else 'bengali'
        
        # Check for Devanagari script (Hindi)
        if re.search(r'[\u0900-\u097F]', text):
            return 'hinglish' if re.search(r'[a-zA-Z0-9]', text) else 'hindi'
        
        # Default to English
        return 'english'
    except:
        return 'english'


def normalize_text(text):
    """Normalize Hinglish and Benglish variations"""
    hinglish_map = {
        r'\bkya\b': 'kya', r'\bhaan\b': 'haan', r'\bnahi\b': 'nahi',
        r'\bacha\b': 'acha', r'\bache\b': 'ache', r'\bbhai\b': 'bhai',
        r'\byaar\b': 'yaar', r'\bthik\b': 'thik'
    }
    
    benglish_map = {
        r'\btumi\b': 'tumi', r'\bami\b': 'ami', r'\bache\b': 'ache',
        r'\beita\b': 'eita', r'\bkoto\b': 'koto', r'\bkothay\b': 'kothay'
    }
    
    normalized = text
    for pattern, replacement in hinglish_map.items():
        normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)
    
    for pattern, replacement in benglish_map.items():
        normalized = re.sub(pattern, replacement, normalized, flags=re.IGNORECASE)
    
    return normalized